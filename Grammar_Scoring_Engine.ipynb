{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This notebook builds a pipeline to evaluate grammar from audio files. It uses OpenAI Whisper for transcription and combines multiple models and metrics to assess language quality.\n",
        "\n",
        "# For each audio input, the following are computed:\n",
        "\n",
        "#     Transcription using Whisper\n",
        "#     Grammar errors (LanguageTool)\n",
        "#     Grammar correction (T5 model)\n",
        "#     BLEU score between original and corrected text\n",
        "#     Grammatical acceptability (CoLA via RoBERTa)\n",
        "#     Fluency score (based on GPT-2 perplexity)\n",
        "#     Readability (Flesch Reading Ease)\n",
        "#     Coherence (semantic similarity between sentences)\n",
        "#     Speech fluency (words per minute vs ideal rate)\n",
        "#     Pronunciation score (based on Word Error Rate)\n",
        "\n",
        "# A weighted final score is generated for each file to summarize overall spoken English proficiency."
      ],
      "metadata": {
        "id": "sXxGMveMS1d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuVbU3H6V_99",
        "outputId": "94e729cd-a2bf-4ece-91c1-2cf62411dcaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchaudio transformers torchmetrics\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q language-tool-python\n",
        "!pip install -q spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install evaluate textstat jiwer\n"
      ],
      "metadata": {
        "id": "35RflehCWLwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a955d5-9e3c-4cdf-d1d0-03fb1a092c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: textstat in /usr/local/lib/python3.11/dist-packages (0.7.5)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.11/dist-packages (from textstat) (0.17.2)\n",
            "Requirement already satisfied: cmudict in /usr/local/lib/python3.11/dist-packages (from textstat) (1.0.32)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from textstat) (75.2.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (8.6.1)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat) (6.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict->textstat) (3.21.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import whisper\n",
        "import librosa\n",
        "import jiwer\n",
        "import spacy\n",
        "import textstat\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import language_tool_python\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration, T5Tokenizer,\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    GPT2LMHeadModel, GPT2Tokenizer\n",
        ")\n",
        "from torchmetrics.text.bleu import BLEUScore\n",
        "from evaluate import load"
      ],
      "metadata": {
        "id": "tzjmyp4LD-gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KrA8mBDEO3j",
        "outputId": "ae81fb47-beca-49ae-ce34-440b54a1e39c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models\n",
        "\n",
        "def init_models():\n",
        "    return {\n",
        "        \"whisper\": whisper.load_model(\"base\"),\n",
        "        \"lt\": language_tool_python.LanguageTool(\"en-US\"),\n",
        "        \"spacy\": spacy.load(\"en_core_web_sm\"),\n",
        "        \"t5_model\": T5ForConditionalGeneration.from_pretrained(\"vennify/t5-base-grammar-correction\").to(device),\n",
        "        \"t5_tokenizer\": T5Tokenizer.from_pretrained(\"vennify/t5-base-grammar-correction\"),\n",
        "        \"bleu\": load(\"bleu\"),\n",
        "        \"cola_tokenizer\": AutoTokenizer.from_pretrained(\"textattack/roberta-base-CoLA\"),\n",
        "        \"cola_model\": AutoModelForSequenceClassification.from_pretrained(\"textattack/roberta-base-CoLA\").to(device),\n",
        "        \"gpt2_tokenizer\": GPT2Tokenizer.from_pretrained(\"gpt2\"),\n",
        "        \"gpt2_model\": GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device),\n",
        "        \"semantic\": SentenceTransformer(\"all-MiniLM-L6-v2\"),\n",
        "        \"transformation\": jiwer.Compose([\n",
        "            jiwer.ToLowerCase(),\n",
        "            jiwer.RemovePunctuation(),\n",
        "            jiwer.Strip(),\n",
        "            jiwer.RemoveMultipleSpaces()\n",
        "        ])\n",
        "    }\n",
        "\n",
        "models = init_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhcBAI4MEUl4",
        "outputId": "8e9fe502-98fb-45b1-af2f-676a333fada9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at textattack/roberta-base-CoLA were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_audio(file_path, models):\n",
        "    whisper_model = models[\"whisper\"]\n",
        "    result = whisper_model.transcribe(file_path, word_timestamps=True)\n",
        "\n",
        "    transcription = result[\"text\"]\n",
        "    segments = result.get(\"segments\", [])\n",
        "\n",
        "    # Duration from Whisper if available\n",
        "    if segments:\n",
        "        start_time = segments[0][\"start\"]\n",
        "        end_time = segments[-1][\"end\"]\n",
        "        duration = end_time - start_time\n",
        "    else:\n",
        "        y, sr = librosa.load(file_path)\n",
        "        duration = librosa.get_duration(y=y, sr=sr)\n",
        "\n",
        "    # Grammar check\n",
        "    # since this is rule based, it might not give desired results in all cases\n",
        "    lt_tool = models[\"lt\"]\n",
        "    matches = lt_tool.check(transcription)\n",
        "    grammar_errors = len(matches)\n",
        "    grammar_score = 1 - grammar_errors / max(len(transcription.split()), 1)\n",
        "\n",
        "    # T5 Grammar correction\n",
        "    input_text = \"fix: \" + transcription\n",
        "    inputs = models[\"t5_tokenizer\"](input_text, return_tensors=\"pt\", truncation=True).to(device)\n",
        "    outputs = models[\"t5_model\"].generate(**inputs, max_new_tokens=128)\n",
        "    corrected_text = models[\"t5_tokenizer\"].decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # BLEU\n",
        "    bleu = models[\"bleu\"].compute(predictions=[corrected_text], references=[[transcription]])[\"bleu\"]\n",
        "\n",
        "    # CoLA\n",
        "    cola_inputs = models[\"cola_tokenizer\"](corrected_text, return_tensors=\"pt\", truncation=True).to(device)\n",
        "    cola_score = torch.softmax(models[\"cola_model\"](**cola_inputs).logits, dim=1)[0][1].item()\n",
        "\n",
        "    # Fluency (perplexity-based)\n",
        "    enc = models[\"gpt2_tokenizer\"](transcription, return_tensors=\"pt\").to(device)\n",
        "    loss = models[\"gpt2_model\"](**enc, labels=enc[\"input_ids\"]).loss\n",
        "    perplexity = torch.exp(loss).item()\n",
        "    fluency_score = 1 / perplexity\n",
        "\n",
        "    # Readability\n",
        "    readability_score = min(max(textstat.flesch_reading_ease(transcription) / 100, 0), 1)\n",
        "\n",
        "    # Coherence\n",
        "    sents = transcription.split(\". \")\n",
        "    sent_vecs = models[\"semantic\"].encode(sents)\n",
        "    coherence = np.mean([np.dot(sent_vecs[i], sent_vecs[i+1]) for i in range(len(sent_vecs)-1)]) if len(sent_vecs) > 1 else 1\n",
        "\n",
        "    # Speech Rate (using Whisper duration)\n",
        "    word_count = len(transcription.split())\n",
        "    wpm = word_count / (duration / 60)\n",
        "    speech_fluency = max(0, 1 - abs(wpm - 140) / 140)\n",
        "\n",
        "    # Pronunciation score\n",
        "    wer = jiwer.wer(models[\"transformation\"](corrected_text), models[\"transformation\"](transcription))\n",
        "    pronunciation = max(0, 1 - wer)\n",
        "\n",
        "    # Final score\n",
        "    final = 0.2 * grammar_score + 0.15 * bleu + 0.15 * cola_score + 0.15 * fluency_score + \\\n",
        "            0.1 * readability_score + 0.1 * coherence + 0.1 * pronunciation\n",
        "\n",
        "    return {\n",
        "        \"Transcription\": transcription,\n",
        "        \"Corrected Text\": corrected_text,\n",
        "        \"Grammar Errors\": grammar_errors,\n",
        "        \"BLEU\": round(bleu, 3),\n",
        "        \"CoLA\": round(cola_score, 3),\n",
        "        \"Fluency\": round(fluency_score, 3),\n",
        "        \"Readability\": round(readability_score, 3),\n",
        "        \"Coherence\": round(coherence, 3),\n",
        "        \"WPM\": round(wpm, 1),\n",
        "        \"Pronunciation\": round(pronunciation, 3),\n",
        "        \"Final Score\": round(final * 100, 3)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "wPzlqm0PElgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_files = [\"good_sample1.m4a\", \"bad_sample1.m4a\"]\n",
        "results = {file: evaluate_audio(file, models) for file in audio_files}\n",
        "\n",
        "df = pd.DataFrame(results).T.transpose()\n",
        "df.columns = audio_files\n",
        "df.index.name = \"Metric\"\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiRvYuiJEpP_",
        "outputId": "2e2bf4e4-09a5-4078-a707-798dab6b7aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 good_sample1.m4a  \\\n",
            "Metric                                                              \n",
            "Transcription    I am delighted to be here today and appreciat...   \n",
            "Corrected Text  I am delighted to be here today and appreciate...   \n",
            "Grammar Errors                                                  0   \n",
            "BLEU                                                        0.802   \n",
            "CoLA                                                        0.973   \n",
            "Fluency                                                     0.067   \n",
            "Readability                                                  0.46   \n",
            "Coherence                                                   0.363   \n",
            "WPM                                                         176.9   \n",
            "Pronunciation                                               0.782   \n",
            "Final Score                                             63.681999   \n",
            "\n",
            "                                                  bad_sample1.m4a  \n",
            "Metric                                                             \n",
            "Transcription    I am delighted to be here today and appreciat...  \n",
            "Corrected Text  I am delighted to be here today and appreciate...  \n",
            "Grammar Errors                                                  0  \n",
            "BLEU                                                        0.646  \n",
            "CoLA                                                        0.975  \n",
            "Fluency                                                     0.038  \n",
            "Readability                                                  0.47  \n",
            "Coherence                                                   0.373  \n",
            "WPM                                                          94.2  \n",
            "Pronunciation                                               0.692  \n",
            "Final Score                                                60.257  \n"
          ]
        }
      ]
    }
  ]
}